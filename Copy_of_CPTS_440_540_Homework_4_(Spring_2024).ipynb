{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TankEngine1234/CPTS440/blob/main/Copy_of_CPTS_440_540_Homework_4_(Spring_2024).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**HOMEWORK 4**\n",
        "\n",
        "Assigned: April 02 (4:00PM)\n",
        "\n",
        "Due: April 16 (11:59PM midnight)\n",
        "\n",
        "This assignment consists five questions. One of them requires you to generate some Python code.\n",
        "\n",
        "--\n",
        "\n",
        "You are expected to:\n",
        "\n",
        "(1) clone the notebook to your own Google Drive;\n",
        "\n",
        "(2) enter your answer and code to the cloned notebook directly; and\n",
        "\n",
        "(3) upload the shareable link of your notebook to Canvas (as your homework submission).\n",
        "\n",
        "**Note that if you forget to enable sharing on your Colab link, we will not be able to grade your work. You must also make sure that the sharing is for Editor rather than Viewer. Otherwise, we will not be able to run your code.**\n",
        "\n",
        "--\n",
        "\n",
        "**Please do NOT attempt to enter your answer directly on the original homework notebook, which is only viewable. Late submission is only possible within one day, and a deduction of 5% per day will be applied.**"
      ],
      "metadata": {
        "id": "cT3FpJuT9n6Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PROBLEM 1** [25pts]\n",
        "\n",
        "Given the following conditional probabilities:\n",
        "\n",
        "$\\mathbf{P}(\\mathrm{WetGrass} \\mid \\mathrm{Sprinkler} \\land \\mathrm{Rain}) = 0.95$\n",
        "\n",
        "$\\mathbf{P}(\\mathrm{WetGrass} \\mid \\mathrm{Sprinkler} \\land \\neg\\mathrm{Rain}) = 0.9$\n",
        "\n",
        "$\\mathbf{P}(\\mathrm{WetGrass} \\mid \\neg\\mathrm{Sprinkler} \\land \\mathrm{Rain}) = 0.8$\n",
        "\n",
        "$\\mathbf{P}(\\mathrm{WetGrass} \\mid \\neg\\mathrm{Sprinkler} \\land \\neg\\mathrm{Rain}) = 0.1$\n",
        "\n",
        "$\\mathbf{P}(\\mathrm{Sprinkler} \\mid \\mathrm{RainySeason} ) = 0.0$\n",
        "\n",
        "$\\mathbf{P}(\\mathrm{Sprinkler} \\mid \\neg\\mathrm{RainySeason} ) = 1.0$\n",
        "\n",
        "$\\mathbf{P}(\\mathrm{Rain} \\mid \\mathrm{RainySeason} ) = 0.9$\n",
        "\n",
        "$\\mathbf{P}(\\mathrm{Rain} \\mid \\neg\\mathrm{RainySeason} ) = 0.1$\n",
        "\n",
        "$\\mathbf{P}(\\mathrm{RainySeason}) = 0.7$\n",
        "\n",
        "For short, let us denote $WG = \\mathrm{WetGrass}$, $S = \\mathrm{Sprinkler}$, $R = \\mathrm{Rain}$, $RS = \\mathrm{RainySeason}$. Answer the following questions:\n",
        "\n",
        "**A.** Show that $P(S) = P(\\neg RS)$ or in other words, $S \\equiv \\neg RS$. [5pts]\n",
        "\n",
        "**B.** Construct a Bayesian Network (BN) with as few parameters as possible (hint: use result of part (A)). You will only get 50% credit for this question if the BN is not optimal in the number of parameters. [10pts]\n",
        "\n",
        "**C.** Compute $P(WG \\land RS \\land \\neg R \\land \\neg S)$. Show step-by-step derivation. [10pts]"
      ],
      "metadata": {
        "id": "OE3YoqLT-Epf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SOLUTION**\n"
      ],
      "metadata": {
        "id": "37KxnmVXgWTk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem 1 Solution\n",
        "A. **bold text**\n",
        "I'll use the law of total probability to find P(S):\n",
        "P(S) = P(S|RS)·P(RS) + P(S|¬RS)·P(¬RS)\n",
        "= 0.0·0.7 + 1.0·0.3\n",
        "= 0 + 0.3\n",
        "= 0.3\n",
        "Now for P(¬RS):\n",
        "P(¬RS) = 1 - P(RS) = 1 - 0.7 = 0.3\n",
        "Since P(S) = P(¬RS) = 0.3, and we know from the given probabilities that:\n",
        "\n",
        "P(S|RS) = 0.0 (sprinkler is never on during rainy season)\n",
        "P(S|¬RS) = 1.0 (sprinkler is always on when not rainy season)\n",
        "\n",
        "This means S and ¬RS are logically equivalent (S ≡ ¬RS), as they have the same probability and perfect correlation.\n",
        "\n",
        "\n",
        "**B.**\n",
        "Given that S ≡ ¬RS from part A, we can optimize the Bayesian Network by removing the redundant node. Since S is deterministically determined by RS, we can simply include RS in our network and derive S from it when needed.\n",
        "The optimal Bayesian Network has the following structure:\n",
        "\n",
        "RainySeason (RS) as a root node\n",
        "Rain (R) depends on RainySeason\n",
        "WetGrass (WG) depends on both Rain (R) and Sprinkler (S), where S = ¬RS\n",
        "\n",
        "This requires the following parameters:\n",
        "\n",
        "P(RS) = 0.7\n",
        "P(R|RS) = 0.9\n",
        "P(R|¬RS) = 0.1\n",
        "P(WG|S,R) = 0.95\n",
        "P(WG|S,¬R) = 0.9\n",
        "P(WG|¬S,R) = 0.8\n",
        "P(WG|¬S,¬R) = 0.1\n",
        "\n",
        "Total number of parameters: 7\n",
        "(Note: We don't need separate parameters for S since S = ¬RS)\n",
        "\n",
        "\n",
        "**C.** Compute P(WG ∧ RS ∧ ¬R ∧ ¬S)\n",
        "I'll solve this step by step using the chain rule for Bayesian Networks:\n",
        "P(WG ∧ RS ∧ ¬R ∧ ¬S) = P(WG|¬S,¬R) · P(¬S|RS) · P(¬R|RS) · P(RS)\n",
        "Let's compute each term:\n",
        "\n",
        "P(WG|¬S,¬R) = 0.1 (given)\n",
        "P(¬S|RS) = 1 - P(S|RS) = 1 - 0 = 1 (since S ≡ ¬RS, when RS is true, S must be false)\n",
        "P(¬R|RS) = 1 - P(R|RS) = 1 - 0.9 = 0.1\n",
        "P(RS) = 0.7 (given)\n",
        "\n",
        "Now, let's multiply these terms:\n",
        "P(WG ∧ RS ∧ ¬R ∧ ¬S) = 0.1 × 1 × 0.1 × 0.7 = 0.007\n",
        "Therefore, P(WG ∧ RS ∧ ¬R ∧ ¬S) = 0.007"
      ],
      "metadata": {
        "id": "CGwD1eRIz3Qx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PROBLEM 2** [20pts]\n",
        "\n",
        "Consider the first-order Markov chain in the figure below. At each step $i$, the (random) state $Z_i$ of the chain at step $i$ can take any values in $\\{0,1,2\\}$. The probability of moving to $Z_{i+1} = v$ from $Z_i = u$ is detailed in the transition matrix in the aforementioned figure.\n",
        "\n",
        "![HW6-Fig-1.png](data:image/png;base64,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)\n",
        "\n",
        "Answer the following questions.\n",
        "\n",
        "**A.** Prove that $P(Z_{i + 1}) = \\sum_{Z_i = 0}^2 P(Z_i) \\ P(Z_{i+1} \\mid Z_i)$ using the chain rule and principle of marginalization. [5pts]\n",
        "\n",
        "**B.** Given the prior probabilities $P(Z_0 = 0) = 0.2$ and $P(Z_0 = 1) = 0.4$, compute the marginal probabilities $P(Z_1 = 0)$, $P(Z_1 = 1)$ and $P(Z_1 = 2)$. [5pts]\n",
        "\n",
        "**C.** Given the same prior probabilities over $Z_0$ as in part (b), compute $P(Z_2 = 0)$, $P(Z_2 = 1)$ and $P(Z_2 = 2)$. [5pts]\n",
        "\n",
        "**D.** Given the same prior probabilities over $Z_0$ as in part (b), compute $P(Z_3 = 0)$, $P(Z_3 = 1)$ and $P(Z_3 = 2)$. [5pts]\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7wndAp_RBgGE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SOLUTION**\n",
        "A. To prove this formula, I'll use the chain rule and marginalization:\n",
        "First, by the chain rule of probability:\n",
        "P(Z₍ᵢ₊₁₎, Zᵢ) = P(Z₍ᵢ₊₁₎|Zᵢ) · P(Zᵢ)\n",
        "Now, by the principle of marginalization, to get P(Z₍ᵢ₊₁₎), I need to sum over all possible values of Zᵢ:\n",
        "P(Z₍ᵢ₊₁₎) = ∑²ₖ₌₀ P(Z₍ᵢ₊₁₎, Zᵢ=k)\n",
        "Substituting the chain rule expression:\n",
        "P(Z₍ᵢ₊₁₎) = ∑²ₖ₌₀ P(Z₍ᵢ₊₁₎|Zᵢ=k) · P(Zᵢ=k)\n",
        "This gives us:\n",
        "P(Z₍ᵢ₊₁₎) = ∑²ₖ₌₀ P(Zᵢ=k) · P(Z₍ᵢ₊₁₎|Zᵢ=k)\n",
        "Which is what we needed to prove.\n",
        "\n",
        "**SOLUTION**\n",
        "B.\n",
        "First, I need to determine P(Z₀=2):\n",
        "P(Z₀=2) = 1 - P(Z₀=0) - P(Z₀=1) = 1 - 0.2 - 0.4 = 0.4\n",
        "\n",
        "Now, I'll use the formula from part A to calculate the marginal probabilities for Z₁:\n",
        "\n",
        "P(Z₁=0) = ∑²ₖ₌₀ P(Z₀=k) · P(Z₁=0|Z₀=k)\n",
        "\n",
        "P(Z₁=0) = P(Z₀=0) · P(Z₁=0|Z₀=0) + P(Z₀=1) · P(Z₁=0|Z₀=1) + P(Z₀=2) · P(Z₁=0|Z₀=2)\n",
        "\n",
        "P(Z₁=0) = 0.2 · 0.3 + 0.4 · 0.1 + 0.4 · 0.3\n",
        "\n",
        "P(Z₁=0) = 0.06 + 0.04 + 0.12 = 0.22\n",
        "\n",
        "\n",
        "P(Z₁=1) = ∑²ₖ₌₀ P(Z₀=k) · P(Z₁=1|Z₀=k)\n",
        "\n",
        "P(Z₁=1) = P(Z₀=0) · P(Z₁=1|Z₀=0) + P(Z₀=1) · P(Z₁=1|Z₀=1) + P(Z₀=2) · P(Z₁=1|Z₀=2)\n",
        "\n",
        "P(Z₁=1) = 0.2 · 0.2 + 0.4 · 0.7 + 0.4 · 0.6\n",
        "\n",
        "P(Z₁=1) = 0.04 + 0.28 + 0.24 = 0.56\n",
        "\n",
        "P(Z₁=2) = ∑²ₖ₌₀ P(Z₀=k) · P(Z₁=2|Z₀=k)\n",
        "\n",
        "P(Z₁=2) = P(Z₀=0) · P(Z₁=2|Z₀=0) + P(Z₀=1) · P(Z₁=2|Z₀=1) + P(Z₀=2) · P(Z₁=2|Z₀=2)\n",
        "\n",
        "P(Z₁=2) = 0.2 · 0.5 + 0.4 · 0.2 + 0.4 · 0.1\n",
        "\n",
        "P(Z₁=2) = 0.1 + 0.08 + 0.04 = 0.22\n",
        "\n",
        "**Therefore:**\n",
        "\n",
        "**P(Z₁=0) = 0.22**\n",
        "\n",
        "**P(Z₁=1) = 0.56**\n",
        "\n",
        "**P(Z₁=2) = 0.22**\n",
        "\n",
        "C Solution.\n",
        "To find these probabilities, I'll use the distribution of Z₁ from part B and apply the same formula:\n",
        "\n",
        "P(Z₂=0) = ∑²ₖ₌₀ P(Z₁=k) · P(Z₂=0|Z₁=k)\n",
        "\n",
        "P(Z₂=0) = P(Z₁=0) · P(Z₂=0|Z₁=0) + P(Z₁=1) · P(Z₂=0|Z₁=1) + P(Z₁=2) · P(Z₂=0|Z₁=2)\n",
        "P(Z₂=0) = 0.22 · 0.3 + 0.56 · 0.1 + 0.22 · 0.3\n",
        "P(Z₂=0) = 0.066 + 0.056 + 0.066 = 0.188\n",
        "\n",
        "P(Z₂=1) = ∑²ₖ₌₀ P(Z₁=k) · P(Z₂=1|Z₁=k)\n",
        "P(Z₂=1) = P(Z₁=0) · P(Z₂=1|Z₁=0) + P(Z₁=1) · P(Z₂=1|Z₁=1) + P(Z₁=2) · P(Z₂=1|Z₁=2)\n",
        "P(Z₂=1) = 0.22 · 0.2 + 0.56 · 0.7 + 0.22 · 0.6\n",
        "P(Z₂=1) = 0.044 + 0.392 + 0.132 = 0.568\n",
        "\n",
        "P(Z₂=2) = ∑²ₖ₌₀ P(Z₁=k) · P(Z₂=2|Z₁=k)\n",
        "P(Z₂=2) = P(Z₁=0) · P(Z₂=2|Z₁=0) + P(Z₁=1) · P(Z₂=2|Z₁=1) + P(Z₁=2) · P(Z₂=2|Z₁=2)\n",
        "P(Z₂=2) = 0.22 · 0.5 + 0.56 · 0.2 + 0.22 · 0.1\n",
        "P(Z₂=2) = 0.11 + 0.112 + 0.022 = 0.244\n",
        "Therefore:\n",
        "P(Z₂=0) = 0.188\n",
        "P(Z₂=1) = 0.568\n",
        "P(Z₂=2) = 0.244\n",
        "\n",
        "D. Given the same prior probabilities over Z₀, compute P(Z₃=0), P(Z₃=1) and P(Z₃=2).\n",
        "Continuing from part C, I'll use the distribution of Z₂ to find Z₃:\n",
        "\n",
        "P(Z₃=0) = ∑²ₖ₌₀ P(Z₂=k) · P(Z₃=0|Z₂=k)\n",
        "P(Z₃=0) = P(Z₂=0) · P(Z₃=0|Z₂=0) + P(Z₂=1) · P(Z₃=0|Z₂=1) + P(Z₂=2) · P(Z₃=0|Z₂=2)\n",
        "P(Z₃=0) = 0.188 · 0.3 + 0.568 · 0.1 + 0.244 · 0.3\n",
        "P(Z₃=0) = 0.0564 + 0.0568 + 0.0732 = 0.1864\n",
        "\n",
        "P(Z₃=1) = ∑²ₖ₌₀ P(Z₂=k) · P(Z₃=1|Z₂=k)\n",
        "P(Z₃=1) = P(Z₂=0) · P(Z₃=1|Z₂=0) + P(Z₂=1) · P(Z₃=1|Z₂=1) + P(Z₂=2) · P(Z₃=1|Z₂=2)\n",
        "P(Z₃=1) = 0.188 · 0.2 + 0.568 · 0.7 + 0.244 · 0.6\n",
        "P(Z₃=1) = 0.0376 + 0.3976 + 0.1464 = 0.5816\n",
        "\n",
        "P(Z₃=2) = ∑²ₖ₌₀ P(Z₂=k) · P(Z₃=2|Z₂=k)\n",
        "P(Z₃=2) = P(Z₂=0) · P(Z₃=2|Z₂=0) + P(Z₂=1) · P(Z₃=2|Z₂=1) + P(Z₂=2) · P(Z₃=2|Z₂=2)\n",
        "P(Z₃=2) = 0.188 · 0.5 + 0.568 · 0.2 + 0.244 · 0.1\n",
        "P(Z₃=2) = 0.094 + 0.1136 + 0.0244 = 0.232\n",
        "\n",
        "**Therefore:**\n",
        "\n",
        "P(Z₃=0) = 0.1864\n",
        "\n",
        "P(Z₃=1) = 0.5816\n",
        "\n",
        "P(Z₃=2) = 0.232\n"
      ],
      "metadata": {
        "id": "TpdrIFcDgZnr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PROBLEM 3** [10pts]\n",
        "\n",
        "Consider the first-order Markov chain in Problem 2 and suppose we have $3$ actions to choose: (1) initializing $Z_0 = 0$; (2) initializing $Z_0 = 1$; and (3) initializing $Z_0 = 2$. Once a decision is made, the Markov chain will simulate forward $2$ steps and stop at a certain (random) state $Z_2$. Answer the following questions.\n",
        "\n",
        "**A.** Suppose that we will be awarded with $5$, $8$ and $10$ units if at the end of the Markov chain simulation, $Z_2 = 0$, $Z_2 = 1$ and $Z_2 = 2$ respectively. Compute the expected reward of each action above. [5pts]\n",
        "\n",
        "**B.** Instead of the above $3$ actions, suppose we are only given $2$ actions A and B.\n",
        "\n",
        "Executing A changes the prior probabilities over $Z_0$ to $(P(Z_0 = 0) = 0.1, P(Z_0 = 1) = 0.9)$.\n",
        "\n",
        "Executing B changes the prior probabilities over $Z_0$ to $(P(Z_0 = 0) = 0.3, P(Z_0 = 2) = 0.7)$.\n",
        "\n",
        "Given the above, compute the expected reward of A and B. Which one is better? Explain. A simple Yes/No answer with no explanation will not be graded.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2GUSxIlWFGfK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SOLUTION**\n",
        "I need to calculate the expected reward for each initialization action by determining the probabilities of ending at each possible Z₂ state, then multiplying by the corresponding rewards.\n",
        "Action (1): Initialize Z₀ = 0\n",
        "\n",
        "First, I'll find the probabilities of Z₂ given Z₀ = 0:\n",
        "For P(Z₂ = 0 | Z₀ = 0):\n",
        "\n",
        "Z₀ = 0 → Z₁ = 0 → Z₂ = 0: P(Z₁ = 0|Z₀ = 0) × P(Z₂ = 0|Z₁ = 0) = 0.3 × 0.3 = 0.09\n",
        "Z₀ = 0 → Z₁ = 1 → Z₂ = 0: P(Z₁ = 1|Z₀ = 0) × P(Z₂ = 0|Z₁ = 1) = 0.2 × 0.1 = 0.02\n",
        "Z₀ = 0 → Z₁ = 2 → Z₂ = 0: P(Z₁ = 2|Z₀ = 0) × P(Z₂ = 0|Z₁ = 2) = 0.5 × 0.3 = 0.15\n",
        "\n",
        "P(Z₂ = 0 | Z₀ = 0) = 0.09 + 0.02 + 0.15 = 0.26\n",
        "\n",
        "For P(Z₂ = 1 | Z₀ = 0):\n",
        "\n",
        "Z₀ = 0 → Z₁ = 0 → Z₂ = 1: P(Z₁ = 0|Z₀ = 0) × P(Z₂ = 1|Z₁ = 0) = 0.3 × 0.2 = 0.06\n",
        "Z₀ = 0 → Z₁ = 1 → Z₂ = 1: P(Z₁ = 1|Z₀ = 0) × P(Z₂ = 1|Z₁ = 1) = 0.2 × 0.7 = 0.14\n",
        "Z₀ = 0 → Z₁ = 2 → Z₂ = 1: P(Z₁ = 2|Z₀ = 0) × P(Z₂ = 1|Z₁ = 2) = 0.5 × 0.6 = 0.30\n",
        "\n",
        "P(Z₂ = 1 | Z₀ = 0) = 0.06 + 0.14 + 0.30 = 0.50\n",
        "For P(Z₂ = 2 | Z₀ = 0):\n",
        "\n",
        "Z₀ = 0 → Z₁ = 0 → Z₂ = 2: P(Z₁ = 0|Z₀ = 0) × P(Z₂ = 2|Z₁ = 0) = 0.3 × 0.5 = 0.15\n",
        "Z₀ = 0 → Z₁ = 1 → Z₂ = 2: P(Z₁ = 1|Z₀ = 0) × P(Z₂ = 2|Z₁ = 1) = 0.2 × 0.2 = 0.04\n",
        "Z₀ = 0 → Z₁ = 2 → Z₂ = 2: P(Z₁ = 2|Z₀ = 0) × P(Z₂ = 2|Z₁ = 2) = 0.5 × 0.1 = 0.05\n",
        "\n",
        "P(Z₂ = 2 | Z₀ = 0) = 0.15 + 0.04 + 0.05 = 0.24\n",
        "\n",
        "Expected reward for Action (1):\n",
        "\n",
        "E[Reward|Z₀=0] = 5 × P(Z₂=0|Z₀=0) + 8 × P(Z₂=1|Z₀=0) + 10 × P(Z₂=2|Z₀=0)\n",
        "\n",
        "E[Reward|Z₀=0] = 5 × 0.26 + 8 × 0.50 + 10 × 0.24\n",
        "\n",
        "E[Reward|Z₀=0] = 1.30 + 4.00 + 2.40 = 7.70\n",
        "\n",
        "Action (2): Initialize Z₀ = 1\n",
        "Following the same approach:\n",
        "For P(Z₂ = 0 | Z₀ = 1):\n",
        "\n",
        "Z₀ = 1 → Z₁ = 0 → Z₂ = 0: P(Z₁ = 0|Z₀ = 1) × P(Z₂ = 0|Z₁ = 0) = 0.1 × 0.3 = 0.03\n",
        "Z₀ = 1 → Z₁ = 1 → Z₂ = 0: P(Z₁ = 1|Z₀ = 1) × P(Z₂ = 0|Z₁ = 1) = 0.7 × 0.1 = 0.07\n",
        "Z₀ = 1 → Z₁ = 2 → Z₂ = 0: P(Z₁ = 2|Z₀ = 1) × P(Z₂ = 0|Z₁ = 2) = 0.2 × 0.3 = 0.06\n",
        "\n",
        "P(Z₂ = 0 | Z₀ = 1) = 0.03 + 0.07 + 0.06 = 0.16\n",
        "For P(Z₂ = 1 | Z₀ = 1):\n",
        "\n",
        "Z₀ = 1 → Z₁ = 0 → Z₂ = 1: P(Z₁ = 0|Z₀ = 1) × P(Z₂ = 1|Z₁ = 0) = 0.1 × 0.2 = 0.02\n",
        "Z₀ = 1 → Z₁ = 1 → Z₂ = 1: P(Z₁ = 1|Z₀ = 1) × P(Z₂ = 1|Z₁ = 1) = 0.7 × 0.7 = 0.49\n",
        "Z₀ = 1 → Z₁ = 2 → Z₂ = 1: P(Z₁ = 2|Z₀ = 1) × P(Z₂ = 1|Z₁ = 2) = 0.2 × 0.6 = 0.12\n",
        "\n",
        "P(Z₂ = 1 | Z₀ = 1) = 0.02 + 0.49 + 0.12 = 0.63\n",
        "For P(Z₂ = 2 | Z₀ = 1):\n",
        "\n",
        "Z₀ = 1 → Z₁ = 0 → Z₂ = 2: P(Z₁ = 0|Z₀ = 1) × P(Z₂ = 2|Z₁ = 0) = 0.1 × 0.5 = 0.05\n",
        "Z₀ = 1 → Z₁ = 1 → Z₂ = 2: P(Z₁ = 1|Z₀ = 1) × P(Z₂ = 2|Z₁ = 1) = 0.7 × 0.2 = 0.14\n",
        "Z₀ = 1 → Z₁ = 2 → Z₂ = 2: P(Z₁ = 2|Z₀ = 1) × P(Z₂ = 2|Z₁ = 2) = 0.2 × 0.1 = 0.02\n",
        "\n",
        "P(Z₂ = 2 | Z₀ = 1) = 0.05 + 0.14 + 0.02 = 0.21\n",
        "\n",
        "Expected reward for Action (2):\n",
        "\n",
        "E[Reward|Z₀=1] = 5 × P(Z₂=0|Z₀=1) + 8 × P(Z₂=1|Z₀=1) + 10 × P(Z₂=2|Z₀=1)\n",
        "\n",
        "E[Reward|Z₀=1] = 5 × 0.16 + 8 × 0.63 + 10 × 0.21\n",
        "\n",
        "E[Reward|Z₀=1] = 0.80 + 5.04 + 2.10 = 7.94\n",
        "\n",
        "Action (3): Initialize Z₀ = 2\n",
        "For P(Z₂ = 0 | Z₀ = 2):\n",
        "\n",
        "Z₀ = 2 → Z₁ = 0 → Z₂ = 0: P(Z₁ = 0|Z₀ = 2) × P(Z₂ = 0|Z₁ = 0) = 0.3 × 0.3 = 0.09\n",
        "Z₀ = 2 → Z₁ = 1 → Z₂ = 0: P(Z₁ = 1|Z₀ = 2) × P(Z₂ = 0|Z₁ = 1) = 0.6 × 0.1 = 0.06\n",
        "Z₀ = 2 → Z₁ = 2 → Z₂ = 0: P(Z₁ = 2|Z₀ = 2) × P(Z₂ = 0|Z₁ = 2) = 0.1 × 0.3 = 0.03\n",
        "\n",
        "P(Z₂ = 0 | Z₀ = 2) = 0.09 + 0.06 + 0.03 = 0.18\n",
        "For P(Z₂ = 1 | Z₀ = 2):\n",
        "\n",
        "Z₀ = 2 → Z₁ = 0 → Z₂ = 1: P(Z₁ = 0|Z₀ = 2) × P(Z₂ = 1|Z₁ = 0) = 0.3 × 0.2 = 0.06\n",
        "Z₀ = 2 → Z₁ = 1 → Z₂ = 1: P(Z₁ = 1|Z₀ = 2) × P(Z₂ = 1|Z₁ = 1) = 0.6 × 0.7 = 0.42\n",
        "Z₀ = 2 → Z₁ = 2 → Z₂ = 1: P(Z₁ = 2|Z₀ = 2) × P(Z₂ = 1|Z₁ = 2) = 0.1 × 0.6 = 0.06\n",
        "\n",
        "P(Z₂ = 1 | Z₀ = 2) = 0.06 + 0.42 + 0.06 = 0.54\n",
        "For P(Z₂ = 2 | Z₀ = 2):\n",
        "\n",
        "Z₀ = 2 → Z₁ = 0 → Z₂ = 2: P(Z₁ = 0|Z₀ = 2) × P(Z₂ = 2|Z₁ = 0) = 0.3 × 0.5 = 0.15\n",
        "Z₀ = 2 → Z₁ = 1 → Z₂ = 2: P(Z₁ = 1|Z₀ = 2) × P(Z₂ = 2|Z₁ = 1) = 0.6 × 0.2 = 0.12\n",
        "Z₀ = 2 → Z₁ = 2 → Z₂ = 2: P(Z₁ = 2|Z₀ = 2) × P(Z₂ = 2|Z₁ = 2) = 0.1 × 0.1 = 0.01\n",
        "\n",
        "P(Z₂ = 2 | Z₀ = 2) = 0.15 + 0.12 + 0.01 = 0.28\n",
        "\n",
        "Expected reward for Action (3):\n",
        "\n",
        "E[Reward|Z₀=2] = 5 × P(Z₂=0|Z₀=2) + 8 × P(Z₂=1|Z₀=2) + 10 × P(Z₂=2|Z₀=2)\n",
        "\n",
        "E[Reward|Z₀=2] = 5 × 0.18 + 8 × 0.54 + 10 × 0.28\n",
        "\n",
        "E[Reward|Z₀=2] = 0.90 + 4.32 + 2.80 = 8.02\n",
        "Therefore, the expected rewards are:\n",
        "\n",
        "Action (1): 7.70 units\n",
        "Action (2): 7.94 units\n",
        "Action (3): 8.02 units"
      ],
      "metadata": {
        "id": "MQN-Y9tRgdXC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PROBLEM 4** [25pts]\n",
        "\n",
        "The loan department of a bank has the following past loan processing records, each of which contains an applicant's income, credit history, debt and the final approval decision. These records can serve as training examples to build a decision-making software for a loan advisory system.\n",
        "\n",
        "| ID | Income   | Credit History | Debt | Decision |\n",
        "|----|----------|----------------|------|----------|\n",
        "| 1  | 0-5K     | Bad            | Low  | Reject   |\n",
        "| 2  | 0-5K     | Good           | Low  | Approve  |\n",
        "| 3  | 0-5K     | Unknown        | High | Reject   |\n",
        "| 4  | 0-5K     | Unknown        | Low  | Approve  |\n",
        "| 5  | 0-5K     | Unknown        | Low  | Approve  |\n",
        "| 6  | 0-5K     | Unknown        | Low  | Reject   |\n",
        "| 7  | 5-10K    | Bad            | Low  | Reject   |\n",
        "| 8  | 5-10K    | Good           | High | Approve  |\n",
        "| 9  | 5-10K    | Unknown        | High | Approve  |\n",
        "| 10 | Over 10K | Unknown        | High | Approve  |\n",
        "| 11 | Over 10K | Bad            | Low  | Reject   |\n",
        "| 12 | Over 10K | Good           | Low  | Approve  |\n",
        "\n",
        "We will build a Naive Bayes classifier in this question.\n",
        "\n",
        "Recall that Naive Bayes inference is based on computing $P(\\mathrm{Cause} | \\mathrm{Effect}_1, \\mathrm{Effect}_2, \\mathrm{Effect}_3)$ while assuming that:\n",
        "\n",
        "**(1)** $\\mathrm{Effect}_1, \\mathrm{Effect}_2$ and $\\mathrm{Effect}_3$ are conditionally independent given $\\mathrm{Cause}$; and\n",
        "\n",
        "**(2)** $P(\\mathrm{Effect}_i \\mid \\mathrm{Cause})$ is given for each effect $\\mathrm{Effect}_i$ as well as $P(\\mathrm{Cause})$.\n",
        "\n",
        "To apply Naive Bayes inference here, we can set $\\mathrm{Cause} = \\mathrm{Decision}$, $\\mathrm{Effect}_1 = \\mathrm{Income}$, $\\mathrm{Effect}_2 = \\mathrm{Credit\\  History}$ and $\\mathrm{Effect}_3 = \\mathrm{Debt}$. However, we are not explicitly provided $P(\\mathrm{Effect}_i \\mid \\mathrm{Cause})$ and $P(\\mathrm{Cause})$.\n",
        "\n",
        "So we need to estimate these probabilities from the data. Given the above context, please answer the following questions.\n",
        "\n",
        "**A.** Estimate $P(\\mathrm{Cause} = \\mathrm{Approve})$ = (no. of approved cases / no. of cases) and $P(\\mathrm{Cause} = \\mathrm{Reject})$ = (no. of rejected cases / no. of cases) from the data. [5pts]\n",
        "\n",
        "**B.** Estimate $P(\\mathrm{Income} = u \\mid \\mathrm{Decision} = \\mathrm{Approve})$ = no. of approved cases where ($\\mathrm{Income} = u$) / no. of approved cases; and $P(\\mathrm{Income} = u \\mid \\mathrm{Decision} = \\mathrm{Reject})$ = no. of rejected cases where ($\\mathrm{Income} = u$) / no. of rejected cases. Do that for each value of $u \\in \\{$0$-$5$\\mathrm{K},\\ $5$-$10$\\mathrm{K},\\  \\mathrm{Over } $10$\\mathrm{K}\\}$. [5pts]\n",
        "\n",
        "**C.** Estimate $P(\\mathrm{Credit\\ History} = u \\mid \\mathrm{Decision} = \\mathrm{Approve})$ = no. of approved cases where ($\\mathrm{Credit\\ History} = u$) / no. of approved cases; and $P(\\mathrm{Credit\\ History} = u \\mid \\mathrm{Decision} = \\mathrm{Reject})$ = no. of rejected cases where ($\\mathrm{Credit\\ History} = u$) / no. of rejected cases. Do that for each value of $u \\in \\{\\mathrm{Bad},\\ \\mathrm{Good},\\  \\mathrm{Unknown}\\}$. [5pts]\n",
        "\n",
        "**D.** Estimate $P(\\mathrm{Debt} = u \\mid \\mathrm{Decision} = \\mathrm{Approve})$ = no. of approved cases where ($\\mathrm{Debt} = u$) / no. of approved cases; and $P(\\mathrm{Debt} = u \\mid \\mathrm{Decision} = \\mathrm{Reject})$ = no. of rejected cases where ($\\mathrm{Debt} = u$) / no. of rejected cases. Do that for each value of $u \\in \\{\\mathrm{Low},\\ \\mathrm{High}\\}$. [5pts]\n",
        "\n",
        "**E.** What is the Naive Bayes decision for an applicant who has $4\\mathrm{K}$ annual income, a good credit and a high amount of debt? [5pts]\n"
      ],
      "metadata": {
        "id": "8qx2dij4IVyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SOLUTION**\n",
        "\n",
        "A. Estimating P(Cause)\n",
        "Total number of cases = 12\n",
        "Number of approved cases = 7\n",
        "Number of rejected cases = 5\n",
        "P(Cause=Approve) = 7/12 = 0.583\n",
        "P(Cause=Reject) = 5/12 = 0.417\n",
        "B. Estimating P(Income=u|Decision)\n",
        "For P(Income=u|Decision=Approve):\n",
        "\n",
        "P(Income=0-5K|Approve) = 3/7 = 0.429\n",
        "P(Income=5-10K|Approve) = 2/7 = 0.286\n",
        "P(Income=Over 10K|Approve) = 2/7 = 0.286\n",
        "\n",
        "For P(Income=u|Decision=Reject):\n",
        "\n",
        "P(Income=0-5K|Reject) = 3/5 = 0.6\n",
        "P(Income=5-10K|Reject) = 1/5 = 0.2\n",
        "P(Income=Over 10K|Reject) = 1/5 = 0.2\n",
        "\n",
        "C. Estimating P(Credit History=u|Decision)\n",
        "For P(Credit History=u|Decision=Approve):\n",
        "\n",
        "P(Credit History=Bad|Approve) = 0/7 = 0\n",
        "P(Credit History=Good|Approve) = 3/7 = 0.429\n",
        "P(Credit History=Unknown|Approve) = 4/7 = 0.571\n",
        "\n",
        "For P(Credit History=u|Decision=Reject):\n",
        "\n",
        "P(Credit History=Bad|Reject) = 3/5 = 0.6\n",
        "P(Credit History=Good|Reject) = 0/5 = 0\n",
        "P(Credit History=Unknown|Reject) = 2/5 = 0.4\n",
        "\n",
        "D. Estimating P(Debt=u|Decision)\n",
        "For P(Debt=u|Decision=Approve):\n",
        "\n",
        "P(Debt=Low|Approve) = 4/7 = 0.571\n",
        "P(Debt=High|Approve) = 3/7 = 0.429\n",
        "\n",
        "For P(Debt=u|Decision=Reject):\n",
        "\n",
        "P(Debt=Low|Reject) = 3/5 = 0.6\n",
        "P(Debt=High|Reject) = 2/5 = 0.4\n",
        "\n",
        "E. Naive Bayes Decision for New Applicant\n",
        "For an applicant with:\n",
        "\n",
        "Income = 4K (falls in the 0-5K category)\n",
        "Credit History = Good\n",
        "Debt = High\n",
        "\n",
        "We need to calculate:\n",
        "P(Approve|Income=0-5K, Credit=Good, Debt=High) and\n",
        "P(Reject|Income=0-5K, Credit=Good, Debt=High)\n",
        "Using Bayes' theorem with the naive independence assumption:\n",
        "P(Approve|Income, Credit, Debt) ∝ P(Approve) × P(Income|Approve) × P(Credit|Approve) × P(Debt|Approve)\n",
        "P(Reject|Income, Credit, Debt) ∝ P(Reject) × P(Income|Reject) × P(Credit|Reject) × P(Debt|Reject)\n",
        "For Approve:\n",
        "P(Approve) × P(Income=0-5K|Approve) × P(Credit=Good|Approve) × P(Debt=High|Approve)\n",
        "= 0.583 × 0.429 × 0.429 × 0.429 = 0.0461\n",
        "For Reject:\n",
        "P(Reject) × P(Income=0-5K|Reject) × P(Credit=Good|Reject) × P(Debt=High|Reject)\n",
        "= 0.417 × 0.6 × 0 × 0.4 = 0\n",
        "Since P(Credit=Good|Reject) = 0, the probability of rejection becomes zero. This is because in our training data, there are no examples where someone with good credit was rejected.\n",
        "\n",
        "Since the probability for Approve (0.0461) is greater than the probability for Reject (0), the Naive Bayes decision would be to Approve the loan for this applicant."
      ],
      "metadata": {
        "id": "7F7oiLcGggvS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PROBLEM 5** [20pts]\n",
        "\n",
        "We will now attempt to implement a Naive Bayes classifier (NBC) to solve a more practical task of spam filtering.\n",
        "\n",
        "In this task, we are given a dataset containing a number of e-mail. Each e-mail is characterized by a string containing its text content, which is labeled with either \"ham\" or \"spam\" where the latter indicates that the e-mail is a spam.\n",
        "\n",
        "You can download this dataset from the assignment statement on Canvas.\n",
        "\n",
        "--\n",
        "\n",
        "To implement NBC, we will first need to decide on a set of features to characterize an e-mail. One approach is to use English words (or tokens) as features. Each e-mail text can then be represented as a multi-hot vector whose dimension is the no. of (distinct) English words.\n",
        "\n",
        "Hence, suppose there are n words/tokens, each e-mail can be represented as a set of variables $X_1, X_2, \\ldots, X_n$ where $X_i = 0$ if the $i$-th word is not present in the e-mail. Otherwise, $X_i = 1$. Likewise, the label of each e-mail $Y = 0$ if it is a normal e-mail. Otherwise, $Y = 1$.\n",
        "\n",
        "Your implementation of the NBC must therefore do the followings:\n",
        "\n",
        "**1.** Decide on the list of words which will be used as features. A few example considerations are: feature word must occur at least once, feature word must be informative, e.g., words such as \"a\", \"an\", \"the\" are not informative.\n",
        "\n",
        "**2.** Estimate $P(X_i \\mid Y)$ given the dataset of example e-mails. This is the part where you \"fit\" the NBC. A manual example has been provided to you in Problem 4.\n",
        "\n",
        "**3.** Given an unseen e-mail (not in the dataset), extract its (input) representation $X_1, X_2, \\ldots, X_n$, compute P(Y \\mid X_1, X_2, \\ldots, X_n) based on the result of step **2.** above, and return the most likely label $Y$. This is the part where the fitted NBC is used for making prediction.\n"
      ],
      "metadata": {
        "id": "XZPp6iZASHDv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For step **1**, you are provided with the following code to remove \"uninformative\" words"
      ],
      "metadata": {
        "id": "cLAPfCAzaV6Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "def clean_util(text):  # the input to this function is a raw e-mail text\n",
        "    punc_rmv = [char for char in text if char not in string.punctuation]\n",
        "    punc_rmv = \"\".join(punc_rmv)\n",
        "    stopword_rmv = [w.strip().lower() for w in punc_rmv.split() if w.strip().lower() not in stopwords.words('english')]\n",
        "    return \" \".join(stopword_rmv)\n",
        "\n",
        "## FILL IN YOUR DATA LOADER & PRE-PROCESSING CODE HERE TO COMPLETE STEP 1\n",
        "## AT THE END OF THIS, YOU SHOULD HAVE THE DATA PACKAGED INTO TRAIN (X_train, Y_train) AND TEST (X_test, Y_test) PARTITIONS AT THE 80/20 RATIO\n",
        "## YOUR NBC WILL BE FITTED USING (X_train, Y_train) AND TESTED ON (X_test, Y_test)\n",
        "\n",
        "## X_train, X_test WILL BE NUMPY MATRICES WITH SIZES (n_train_samples by n_features) AND (n_test_samples by n_features)\n",
        "## y_train, y_test WILL BE NUMPY MATRICES WITH SIZES (n_train_samples by 1) AND (n_test_samples by 1)\n",
        "\n",
        "# --- Cell 2 --------------------------------------------------\n",
        "df = pd.read_csv(\"spam_ham.csv\")[[\"text\", \"label_num\"]]\n",
        "df.columns = [\"text\", \"label\"]          # 0 = ham, 1 = spam\n",
        "\n",
        "# Each column after vectorising is a **word feature** (n ≈ 22 k)\n",
        "vectorizer = CountVectorizer(\n",
        "    preprocessor=clean_util,\n",
        "    binary=True,        # Bernoulli 0/1\n",
        "    min_df=3,           # ignore ultra-rare words\n",
        "    max_df=0.90         # ignore super-common ones\n",
        ")\n",
        "X = vectorizer.fit_transform(df[\"text\"])\n",
        "y = df[\"label\"].to_numpy()\n",
        "\n",
        "# Save the original row indices before splitting\n",
        "indices = np.arange(len(df))\n",
        "\n",
        "X_train, X_test, y_train, y_test, idx_train, idx_test = train_test_split(\n",
        "    X, y, indices, test_size=0.20, random_state=42, stratify=y)\n",
        "\n",
        "print(\"✅ data split:\", X_train.shape, X_test.shape)\n"
      ],
      "metadata": {
        "id": "XSQM1sr0aefg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac604cf3-0181-420d-a530-2b6b967a76b1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ data split: (4136, 14091) (1035, 14091)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For step **2** and step **3**, you are to substantiate the following NBC class"
      ],
      "metadata": {
        "id": "k9-9tIcOa3gQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NBC:\n",
        "    def __init__(self, params=None):  # IT IS UP TO YOU TO DECIDE HOW TO INTERPRET AND UNPACK PARAMS\n",
        "        self.params = params  # IT CAN BE NONE OR IT CAN BE SOME OTHER HYPER-PARAMETERS YOU NEED FOR THE FITTING CODE -- THIS DEPENDS ON YOUR FEATURIZATION DESIGN\n",
        "        self.class_priors = None\n",
        "        self.feature_probs = None\n",
        "\n",
        "    def fit(self, X_train, y_train):\n",
        "        y_train = y_train.ravel()\n",
        "\n",
        "        n_samples, n_features = X_train.shape\n",
        "        self.class_priors = {}\n",
        "        self.feature_probs = {}\n",
        "\n",
        "        self.class_priors[0] = np.mean(y_train == 0)\n",
        "        self.class_priors[1] = np.mean(y_train == 1)\n",
        "\n",
        "        self.feature_probs = {\n",
        "            0: np.asarray((X_train[y_train == 0].sum(axis=0) + 1) / (np.sum(y_train == 0) + 2)).ravel(),\n",
        "            1: np.asarray((X_train[y_train == 1].sum(axis=0) + 1) / (np.sum(y_train == 1) + 2)).ravel(),\n",
        "        }\n",
        "\n",
        "\n",
        "        return self\n",
        "\n",
        "        # Laplace smoothing added (+1 in numerator, +2 in denominator)\n",
        "\n",
        "    def predict(self, X_test):\n",
        "        # Convert sparse matrix to dense NumPy array\n",
        "        X = X_test.toarray()\n",
        "\n",
        "        # Get log probabilities\n",
        "        log_prob_0 = np.log(self.feature_probs[0])\n",
        "        log_prob_1 = np.log(self.feature_probs[1])\n",
        "        log_inv_prob_0 = np.log(1 - self.feature_probs[0])\n",
        "        log_inv_prob_1 = np.log(1 - self.feature_probs[1])\n",
        "\n",
        "        # Log priors\n",
        "        log_prior_0 = np.log(self.class_priors[0])\n",
        "        log_prior_1 = np.log(self.class_priors[1])\n",
        "\n",
        "        # Vectorized computation for all test samples\n",
        "        log_likelihood_0 = X @ log_prob_0 + (1 - X) @ log_inv_prob_0\n",
        "        log_likelihood_1 = X @ log_prob_1 + (1 - X) @ log_inv_prob_1\n",
        "\n",
        "        total_log_0 = log_prior_0 + log_likelihood_0\n",
        "        total_log_1 = log_prior_1 + log_likelihood_1\n",
        "\n",
        "        return (total_log_1 > total_log_0).astype(int)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def evaluate(self, NBC, X_test, y_test): # SEE THE DEFINITION OF X_test, y_test ABOVE\n",
        "    ## FILL IN YOUR IMPLEMENTATION OF THE EVALUATION CODE ##\n",
        "    ## THIS IS SUPPOSED TO RETURN THE A NUMBER BETWEEN 0 and 1 INDICATING THE ACC OF THE FITTED NBC ON THE (X_test, y_test) DATA\n",
        "    y_pred = self.predict(X_test)\n",
        "    acc = np.mean(y_pred == y_test)\n",
        "    return acc\n",
        "    return 0.0  # 0.0 means zero acc while 1.0 means perfect acc\n",
        "\n",
        "# Train the model\n",
        "model = NBC().fit(X_train, y_train)\n",
        "\n",
        "# Call the official evaluate function\n",
        "acc = evaluate(model, None, X_test, y_test)\n",
        "print(\"Test accuracy =\", acc)\n",
        "\n",
        "# Inspect first five test e-mails\n",
        "sample_emails   = X_test[:5]\n",
        "true_labels     = y_test[:5]\n",
        "predicted_labels = model.predict(sample_emails)\n",
        "\n",
        "for i in range(5):\n",
        "    print(f\"Email {i+1}: true={true_labels[i]}, predicted={predicted_labels[i]}\")\n",
        "\n",
        "# --- Cell 5 ----------------------------------------\n",
        "for i in range(5):\n",
        "    print(\"\\n------- Email\", i + 1, \"-------\")\n",
        "    print(df.loc[idx_test[i], \"text\"][:250], \"…\")\n",
        "    print(\"True:\", y_test[i], \"| Predicted:\", model.predict(X_test[i])[0])\n",
        "\n",
        "\n",
        "# Show first 5 spam-labeled emails\n",
        "for i in range(len(y_test)):\n",
        "    if y_test[i] == 1:\n",
        "        pred = model.predict(X_test[i])[0]\n",
        "        print(f\"\\nSpam email {i+1}:\")\n",
        "        print(df.loc[idx_test[i], \"text\"][:300])\n",
        "        print(\"True:\", y_test[i], \"| Predicted:\", pred)\n",
        "        break  # remove this to see more\n",
        "\n"
      ],
      "metadata": {
        "id": "2J9i1rY-bQWA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3281bc08-74a8-43c4-eed9-3588dd1d1c78"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy = 0.8975845410628019\n",
            "Email 1: true=0, predicted=0\n",
            "Email 2: true=0, predicted=0\n",
            "Email 3: true=0, predicted=0\n",
            "Email 4: true=0, predicted=0\n",
            "Email 5: true=0, predicted=0\n",
            "\n",
            "------- Email 1 -------\n",
            "Subject: final cp name change and merger report 08 / 00\r\n",
            "just to clarify , i was in the february 2000 report in error when i sent the\r\n",
            "report out to everyone . please notice at the bottom of the report that there\r\n",
            "is a worksheet tab for august 2000 a …\n",
            "True: 0 | Predicted: 0\n",
            "\n",
            "------- Email 2 -------\n",
            "Subject: calpine daily gas nomination\r\n",
            "- hidalgo daily gas nomination . doc …\n",
            "True: 0 | Predicted: 0\n",
            "\n",
            "------- Email 3 -------\n",
            "Subject: calpine daily gas nomination\r\n",
            ">\r\n",
            "aimee , i will be out of the office friday and monday . in my absence please\r\n",
            "call aron childers at 713 - 830 - 8811 if you have any questions . thanks .\r\n",
            "ricky a . archer\r\n",
            "fuel supply\r\n",
            "700 louisiana , suite  …\n",
            "True: 0 | Predicted: 0\n",
            "\n",
            "------- Email 4 -------\n",
            "Subject: wells\r\n",
            "daren , i think i may have lost my mind ( no comment vance ) but did i talk to\r\n",
            "you about meter 6789 taking that volume from 12079 to 1200 . also yates has\r\n",
            "averaged around the 3366 that they want to bring the volume down to . let me\r …\n",
            "True: 0 | Predicted: 0\n",
            "\n",
            "------- Email 5 -------\n",
            "Subject: first deliveries - comstock oil & gas and hesco gathering company\r\n",
            "see attached letters …\n",
            "True: 0 | Predicted: 0\n",
            "\n",
            "Spam email 6:\n",
            "Subject: 3 . 25 rate confirmation # 367886924 jb wed , 29 jun 2005 09 : 35 : 02 - 0800\r\n",
            "hello ,\r\n",
            "we sent you an email a while ago , because you now qualify\r\n",
            "for a much lower rate based on the biggest rate drop in years .\r\n",
            "you can now get $ 327 , 000 for as little as $ 617 a month !\r\n",
            "bad credit ? doe\n",
            "True: 1 | Predicted: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Important notes:**\n",
        "\n",
        "**1.** For step **1**, feel free to use any existing text preprocessing workflow of scikit-learn.\n",
        "\n",
        "**2.** For step **2** and **3**, you are expected to implement NBC from scratch. If you call the default NBC from scikit-learn or any other libraries, your submission will be voided. You are NOT allowed to change the above function signatures but you are allowed to add extra functions to the NBC class.\n",
        "\n",
        "**3.** Please also do NOT attempt to \"work around\" the above rules. Unless you really implement NBC from scratch, any \"work around\" will result in a zero score."
      ],
      "metadata": {
        "id": "uU2mIThLef38"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"spam_ham.csv\")\n",
        "print(\"Column names:\", df.columns.tolist())\n",
        "df.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "vj-nZqQYjhP5",
        "outputId": "6c973c44-7456-49eb-f100-893643c82079"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Column names: ['Unnamed: 0', 'label', 'text', 'label_num']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0 label                                               text  \\\n",
              "0         605   ham  Subject: enron methanol ; meter # : 988291\\r\\n...   \n",
              "1        2349   ham  Subject: hpl nom for january 9 , 2001\\r\\n( see...   \n",
              "2        3624   ham  Subject: neon retreat\\r\\nho ho ho , we ' re ar...   \n",
              "3        4685  spam  Subject: photoshop , windows , office . cheap ...   \n",
              "4        2030   ham  Subject: re : indian springs\\r\\nthis deal is t...   \n",
              "\n",
              "   label_num  \n",
              "0          0  \n",
              "1          0  \n",
              "2          0  \n",
              "3          1  \n",
              "4          0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c7b858cd-793f-4811-b1b4-92f9efbff290\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "      <th>label_num</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>605</td>\n",
              "      <td>ham</td>\n",
              "      <td>Subject: enron methanol ; meter # : 988291\\r\\n...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2349</td>\n",
              "      <td>ham</td>\n",
              "      <td>Subject: hpl nom for january 9 , 2001\\r\\n( see...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3624</td>\n",
              "      <td>ham</td>\n",
              "      <td>Subject: neon retreat\\r\\nho ho ho , we ' re ar...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4685</td>\n",
              "      <td>spam</td>\n",
              "      <td>Subject: photoshop , windows , office . cheap ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2030</td>\n",
              "      <td>ham</td>\n",
              "      <td>Subject: re : indian springs\\r\\nthis deal is t...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c7b858cd-793f-4811-b1b4-92f9efbff290')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c7b858cd-793f-4811-b1b4-92f9efbff290 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c7b858cd-793f-4811-b1b4-92f9efbff290');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-189734b0-0555-432b-b13a-d9063b5ddaf0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-189734b0-0555-432b-b13a-d9063b5ddaf0')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-189734b0-0555-432b-b13a-d9063b5ddaf0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5171,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1492,\n        \"min\": 0,\n        \"max\": 5170,\n        \"num_unique_values\": 5171,\n        \"samples\": [\n          2924,\n          3839,\n          3078\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"spam\",\n          \"ham\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4993,\n        \"samples\": [\n          \"Subject: hpl / conoco - teco waha 03 / 23 / 01 purchase\\r\\ndaren , conoco invoiced hpl at $ 5 . 87 for 03 / 23 at pgev / waha and deal ticket 685350 shows $ 4 . 87 . can you confirm the price ? thanks .\",\n          \"Subject: holiday on - call data\\r\\npipeline contact phone fax pager\\r\\nblack marlin blair lichentwalter 713 853 - 7367 713 646 - 3201 ( h )\\r\\n281 370 - 1866\\r\\ndebbie thompson 713 853 - 3144 713 646 - 3201\\r\\n( noms due today for 23 rd through 27 th )\\r\\nchannel jim tobacco 713 420 - 2159\\r\\ngas control 1 505 599 - 2333\\r\\n( open thursday . noms will be due through monday )\\r\\ncentana william spekels 713 627 - 6290 713 762 - 3450\\r\\ndonna spencer 713 627 - 6255\\r\\ngas control 1 888 204 - 1718\\r\\n( noms due today for 23 rd through 27 th )\\r\\nduke energy annette anderson 713 260 - 8603 713 949 - 3026\\r\\n( on call ) bob moseman 713 - 260 - 8698 ( thursday )\\r\\nopen tomorrow - noms will be due thru the 27 th )\\r\\nlonestar gary gafford 214 670 - 2674 214 875 - 3810\\r\\ngas control 214 875 - 2455 or 2456\\r\\n( noms due today , 23 rd thru 27 th )\\r\\nnorthern natural ben markey 853 - 7581 cell 713 446 - 9404 800 931 - 0398\\r\\n( on call ) charlie mosey 853 - 1520\\r\\ngas control 853 -\\r\\n( open thursday - noms due thru 27 th . )\\r\\neast trans - east texas\\r\\ntejas gas control 713 767 - 5366\\r\\npaula svehla 713 230 - 3569\\r\\nmickey chapman 713 230 - 3546\\r\\n( open thursday - noms due thru 27 th )\\r\\nmidcon ( y 2 k ) ken nachlinger 713 369 - 9284 713 369 - 9375 888 733 - 5954\\r\\n( on call ) steven 888 790 - 0255\\r\\n( y 2 k ) don 888 733 - 4602\\r\\ngas control 713 369 - 9200\\r\\n( noms due today , 23 rd thru 27 th )\\r\\nmoss bluff no current business\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label_num\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    }
  ]
}